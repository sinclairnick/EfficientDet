{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/nick/Documents/school/research/EfficientLPR')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from rapidfuzz import fuzz\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2_norm(y_trues, y_preds):\n",
    "    distances = []\n",
    "    for i in range(len(y_preds)): # calculate euclidian distance between preds and answer\n",
    "        y_true, y_pred = y_trues[i], y_preds[i]\n",
    "        distances.append(np.linalg.norm(y_true - y_pred))\n",
    "    return np.expand_dims(distances,1)\n",
    "\n",
    "def get_lev_distance(y_true, y_preds):\n",
    "    lev_distances = []\n",
    "    for row in np.hstack([np.expand_dims(y_preds, 1), np.expand_dims(y_true, 1)]):\n",
    "        lev_distances.append(fuzz.ratio(row[0], row[1]))\n",
    "    return np.expand_dims(lev_distances,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LP Exact Accuracy: 0.74%\n[0.93282828 2.00462905 1.44303702]\n[0.18693939 2.22114485 6.90363906]\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script that transforms the predictions into three features:\n",
    "    lp_distance: a similarity metric representing the levenshtein distance between true and predicted LP\n",
    "    body_distance: distance between true and predicted body\n",
    "    color_distance: distance between true and predicted color\n",
    "\n",
    "\"\"\"\n",
    "test = True\n",
    "\n",
    "predictions_path = f'predictions_nzvd_{\"test\" if test else \"train\"}.full.csv'\n",
    "trues_path = f'data/processed/nzvd/{\"test\" if test else \"train\"}_annotations.csv'\n",
    "lps_path = f'data/raw/nzvd/{\"test\" if test else \"train\"}_labels.csv'\n",
    "classes_path = 'data/processed/classes.csv'\n",
    "colors_path = 'data/processed/colors.csv'\n",
    "\n",
    "# get class data\n",
    "classes = [x[0] for x in pd.read_csv(classes_path, header=None).values]\n",
    "colors = [x[0] for x in pd.read_csv(colors_path, header=None).values]\n",
    "class_labels = {x:i for i,x in enumerate(classes)}\n",
    "color_labels = {x:i for i,x in enumerate(colors)}\n",
    "\n",
    "# get y_pred \n",
    "preds = pd.read_csv(predictions_path)\n",
    "preds = preds.fillna('') # fill NaN values with empty string\n",
    "\n",
    "# get y_true\n",
    "lps = pd.read_csv(lps_path)[['lp-string']].T.squeeze()\n",
    "lps = lps.apply(lambda x: str(x).replace(' ', ''))\n",
    "trues = pd.read_csv(trues_path, header=None)\n",
    "if 'train' in trues_path:\n",
    "    trues = pd.concat([trues, pd.read_csv(trues_path.replace('train', 'val'), header=None)])\n",
    "trues.columns = ['file', 't', 'l', 'h', 'w', 'body', 'color']\n",
    "trues = trues.sort_values(by=['file'])\n",
    "trues.reset_index(inplace=True)\n",
    "trues = trues.assign(lp=lps)\n",
    "\n",
    "\n",
    "# LICENSE PLATES    \n",
    "lp_true, lp_pred = trues[['lp']].values.squeeze(), preds[['lp']].values.squeeze()\n",
    "lp_acc = np.mean([lp_true == lp_pred])\n",
    "print(\"LP Exact Accuracy:\", f'{lp_acc}%', )\n",
    "\n",
    "def featurize(trues, preds):\n",
    "    \"\"\"Converts [preds, true] into [levenshtein distance, CCE_body, CCE_color]\"\"\"\n",
    "\n",
    "    # levenshtein distance of license plates\n",
    "    lev_distances = get_lev_distance(trues[['lp']].values.squeeze(), preds[['lp']].values.squeeze())\n",
    "\n",
    "    # BODY\n",
    "    body_true = list(map(lambda x: class_labels[x], trues[['body']].values.squeeze().tolist()))\n",
    "    body_true = tf.one_hot(body_true, depth=len(class_labels))\n",
    "    body_headers = [header for header in preds.columns if header.startswith('body')]\n",
    "    body_pred = preds[body_headers].values\n",
    "    # body_pred = (np.argmax(body_pred, axis=1) == np.expand_dims(body_true, 0)).T\n",
    "    body_cce = np.expand_dims(tf.losses.categorical_crossentropy(body_true, body_pred).numpy(), 1)\n",
    "\n",
    "\n",
    "    # COLOR\n",
    "    color_true = list(map(lambda x: color_labels[x], trues[['color']].values.squeeze().tolist()))\n",
    "    color_true = tf.one_hot(color_true, depth=len(color_labels))\n",
    "    color_headers = [header for header in preds.columns if header.startswith('color')]\n",
    "    color_pred = preds[color_headers].values\n",
    "    # color_pred = (np.argmax(color_pred, axis=1) == np.expand_dims(color_true,0)).T\n",
    "    color_cce = np.expand_dims(tf.losses.categorical_crossentropy(color_true, color_pred).numpy(), 1)\n",
    "\n",
    "    return [lev_distances/100, color_cce, body_cce]\n",
    "\n",
    "y_positive = np.expand_dims(np.repeat([1], len(preds)), 1) # positive samples have class==1\n",
    "x_positive = np.hstack(featurize(trues, preds))\n",
    "x_negative = np.empty((0,3))\n",
    "y_negative = np.empty((0,1))\n",
    "\n",
    "# create negatives\n",
    "for i, sample in enumerate(trues.iloc):\n",
    "    \"\"\" Create negative samples. For each true sample, pair with every non-matching sample \"\"\"\n",
    "    headers = sample.index.values\n",
    "    neg_true = [sample.values for _ in range(len(trues)-1)]\n",
    "    neg_true = pd.DataFrame(neg_true, columns=headers)\n",
    "    # add all preds except current sample\n",
    "    neg_pred = pd.concat([preds.iloc[:i], preds.iloc[i+1:]])\n",
    "    neg_x = featurize(neg_true, neg_pred)\n",
    "    neg_x = np.hstack(neg_x)\n",
    "    neg_y = np.zeros((len(neg_x), 1))\n",
    "\n",
    "    x_negative = np.concatenate([x_negative, neg_x])\n",
    "    y_negative = np.concatenate([y_negative, neg_y])\n",
    "\n",
    "x_negative = np.array(x_negative)\n",
    "y_negative = np.array(y_negative)\n",
    "# balance data\n",
    "neg_idxs = np.random.randint(0, len(x_positive), len(x_positive))\n",
    "x_negative = x_negative[neg_idxs]\n",
    "y_negative = y_negative[neg_idxs]\n",
    "\n",
    "x = np.vstack([x_positive, x_negative])\n",
    "y = np.vstack([y_positive, y_negative])\n",
    "\n",
    "print(np.mean(x_positive, axis=0))\n",
    "print(np.mean(x_negative, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [10, -1, -1]\n",
    "def similarity(x):\n",
    "    return np.dot(x, betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Score acc 0.84\n1.0\n0.84\n0.92\n"
    }
   ],
   "source": [
    "threshold = 4\n",
    "\n",
    "score_accs = []\n",
    "\n",
    "# compare each prediction against entire GT \"database\"\n",
    "for i, prediction in enumerate(preds.iloc):\n",
    "    # initialize y_array\n",
    "    y_true = np.zeros(len(trues))\n",
    "    # set single true match\n",
    "    y_true[i] = 1\n",
    "    # repeat sample\n",
    "    colnames = prediction.index.values\n",
    "    prediction = prediction.values\n",
    "    x_pred = [prediction for _ in range(len(trues))]\n",
    "    x_pred = pd.DataFrame(x_pred, columns=colnames)\n",
    "\n",
    "    # compare sample against all samples\n",
    "    x_pred = featurize(trues, x_pred)\n",
    "    x_pred = np.hstack(x_pred)\n",
    "\n",
    "    score = similarity(x_pred)\n",
    "    imax = np.argmax(score)\n",
    "    score_accs.append(y_true[imax] == 1)\n",
    "print('Score acc', np.mean(score_accs))\n",
    "\n",
    "prec = tf.metrics.Precision()\n",
    "rec = tf.metrics.Recall()\n",
    "acc = tf.metrics.Accuracy()\n",
    "\n",
    "for x_, y_ in zip(x, y):\n",
    "    if similarity(x_) > threshold:\n",
    "        prec.update_state(y_,[1])\n",
    "        rec.update_state(y_,[1])\n",
    "        acc.update_state(y_,[1])\n",
    "    else:\n",
    "        prec.update_state(y_,[0])\n",
    "        rec.update_state(y_,[0])\n",
    "        acc.update_state(y_,[0])\n",
    "print(prec.result().numpy())\n",
    "print(rec.result().numpy())\n",
    "print(acc.result().numpy())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitanaconda3virtualenvc7eb3ab0ecc14188bea54639f0fd4b91",
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}